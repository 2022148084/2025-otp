import os
import hashlib
import redis
from datetime import datetime
from pydantic import BaseModel, Field
from openai import OpenAI
from app.core.config import settings

# ---------------------------------------------------------
# [ë²„ì „ ê´€ë¦¬]
# ---------------------------------------------------------
PROMPT_VERSION = "v1"  # í”„ë¡¬í”„íŠ¸ ë³€ê²½ ì‹œ ì´ê²ƒë§Œ ì˜¬ë¦¬ë©´ ë¨
MODEL_VERSION = "gpt-5.1"

# ---------------------------------------------------------
# [Redis í´ë¼ì´ì–¸íŠ¸ ì„¤ì •]
# ---------------------------------------------------------
# Docker í™˜ê²½ì—ì„œëŠ” 'redis', ë¡œì»¬/ê¸°íƒ€ í™˜ê²½ ëŒ€ë¹„ í™˜ê²½ë³€ìˆ˜ ì§€ì›
redis_host = os.getenv("REDIS_HOST", "redis")

try:
    # decode_responses=True: ë°ì´í„°ë¥¼ bytesê°€ ì•„ë‹Œ strë¡œ ìë™ ë³€í™˜
    redis_client = redis.Redis(host=redis_host, port=6379, db=0, decode_responses=True)
    # ì—°ê²° í…ŒìŠ¤íŠ¸ (í•‘) - ì‹¤íŒ¨ ì‹œ ì˜ˆì™¸ ë°œìƒí•˜ì—¬ redis_clientë¥¼ Noneìœ¼ë¡œ ì²˜ë¦¬
    redis_client.ping()
    print(f"âœ… Redis connected at {redis_host}")
except Exception as e:
    print(f"âš ï¸ Redis connection failed: {e}")
    redis_client = None


# ---------------------------------------------------------
# [ë°ì´í„° ëª¨ë¸ ì •ì˜]
# ---------------------------------------------------------

class Metadata(BaseModel):
    location: str = Field(description="í•µì‹¬ ì§€ì—­ëª… (ì˜ˆ: ê°•ë‚¨ì—­, í™ëŒ€). ì¶œêµ¬ ë²ˆí˜¸ë‚˜ ì„¸ë¶€ ìœ„ì¹˜ ì œì™¸.")
    group_name: str = Field(description="ëª¨ì„ ì¸ì› (í¬ë§·: 'ì¹œêµ¬ Nì¸'). ëŒ€í™” ì°¸ì—¬ì ìˆ˜ë¥¼ ì„¸ì–´ì„œ ì‘ì„±.")
    date: str = Field(description="ì•½ì† ë‚ ì§œ (ë¬´ì¡°ê±´ '2025ë…„ 12ì›” 7ì¼'ë¡œ ê³ ì •)")

class Persona(BaseModel):
    name: str = Field(description="ì°¸ì—¬ì ì´ë¦„ (ì˜ˆ: 'ë‚˜', 'ì–´í”¼ì¹˜')")
    likes: list[str] = Field(description="ì„ í˜¸í•˜ëŠ” ìŒì‹, ë¶„ìœ„ê¸°, í™œë™ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: ['í•œì‹', 'ì¡°ìš©í•œ', 'ì‚¬ì§„'])")
    dislikes: list[str] = Field(description="ì‹«ì–´í•˜ê±°ë‚˜ í”¼í•˜ëŠ” ê²ƒë“¤ ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: ['ì‹œë„ëŸ¬ìš´ ê³³', 'í•´ì‚°ë¬¼', 'ì›¨ì´íŒ…'])")

class CourseStep(BaseModel):
    step: int = Field(description="ë‹¨ê³„ (1: ì‹ì‚¬, 2: ì¹´í˜, 3: ë†€ê±°ë¦¬/ìˆ )")
    category: str = Field(description="ì¹´í…Œê³ ë¦¬ (ì‹ë‹¹, ì¹´í˜, ì´ìì¹´ì•¼ ë“±)")
    final_query: str = Field(description="ë„¤ì´ë²„ ê²€ìƒ‰ìš© ìµœì¢… ë¬¸ìì—´ (4ë‹¨ì–´ ì´í•˜)")

class AnalysisResult(BaseModel):
    metadata: Metadata
    personas: list[Persona]
    courses: list[CourseStep]


def analyze_text_with_llm(text: str) -> AnalysisResult:
    """
    ì¹´í†¡ ëŒ€í™”ë¥¼ ë¶„ì„í•˜ì—¬ ë©”íƒ€ë°ì´í„°, ìƒì„¸ í˜ë¥´ì†Œë‚˜(ì„ í˜¸/ë¹„ì„ í˜¸), 3ë‹¨ê³„ ì¶”ì²œ ì½”ìŠ¤ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    (Redis ìºì‹± ì ìš©: ë™ì¼í•œ í…ìŠ¤íŠ¸ ìš”ì²­ ì‹œ OpenAI í˜¸ì¶œ ì—†ì´ ë°˜í™˜)
    """
    
    if not settings.OPENAI_API_KEY:
        raise ValueError("âŒ OpenAI API Keyê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤! .env íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")

    # ---------------------------------------------------------
    # [Cache Check] Redis ì¡°íšŒ
    # ---------------------------------------------------------
    cache_key = ""
    if redis_client:
        try:
            # ë²„ì „ ì •ë³´ë¥¼ í¬í•¨í•œ ìºì‹œ í‚¤ ìƒì„±
            cache_input = f"{PROMPT_VERSION}:{MODEL_VERSION}:{text}"
            text_hash = hashlib.md5(cache_input.encode('utf-8')).hexdigest()
            cache_key = f"llm_analysis:{text_hash}"
            
            cached_data = redis_client.get(cache_key)
            if cached_data:
                print(f"âš¡ï¸ [Redis Hit] ìºì‹œëœ LLM ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤. (Key: {cache_key})")
                # JSON ë¬¸ìì—´ì„ Pydantic ê°ì²´ë¡œ ë³µì›
                return AnalysisResult.model_validate_json(cached_data)
        except Exception as e:
            print(f"âš ï¸ Redis Read Error: {e}")

    # ---------------------------------------------------------
    # [LLM Call] OpenAI í˜¸ì¶œ (Cache Miss)
    # ---------------------------------------------------------
    print("ğŸ¤– [Redis Miss] OpenAI API í˜¸ì¶œ ì¤‘...")
    client = OpenAI(api_key=settings.OPENAI_API_KEY)

    # í”„ë¡¬í”„íŠ¸ ì›ë³¸ ìœ ì§€
    system_prompt = """
    Role: You are a "Search Query Architect" & "Persona Analyst".
    
    Task:
    1. Metadata: Extract Location. Count participants for Group Name. **FORCE** Date.
    2. Persona: Identify ALL participants. Extract their 'Likes' and 'Dislikes' as keyword lists.
    3. Course: Generate a 3-step course (Meal -> Cafe -> Activity/Pub).
    4. Query Construction: Create 'final_query' based on Critical Rules.

    # ğŸ”´ Critical Rules:

    [Metadata Rules]
    - Location: Extract ONLY the main area (e.g., "ê°•ë‚¨ì—­", "í™ëŒ€"). Remove details like "Exit 3".
    - Group Name: Count the number of unique speakers in the chat and format strictly as "ì¹œêµ¬ Nì¸" (e.g., "ì¹œêµ¬ 2ì¸", "ì¹œêµ¬ 3ì¸", "ì¹œêµ¬ 4ì¸"). Do NOT use terms like "Couples", "Family", or "Colleagues".
    - Date: ALWAYS set to "2025ë…„ 12ì›” 7ì¼". (Do not extract from chat)

    [Persona Rules]
    - Identify ALL participants involved in the conversation.
    - 'likes': Extract 2-4 keywords (List of Strings) about what they like (Food type, Atmosphere, Activity).
    - 'dislikes': Extract 1-3 keywords (List of Strings) about what they dislike or want to avoid. If not mentioned, infer reasonable dislikes based on context (e.g., if they like quiet places, they likely dislike 'Noise').

    [Query Generation Rules for 'final_query']
    
    [Step 1 (Meal) & Step 2 (Cafe)]
    - Format: "{Location} {Adjective} {Noun}"
    - Rule: Must include exactly ONE adjective.
    - Ban List: "Expensive"(ë¹„ì‹¼), "Cheap"(ì‹¼), "Delicious"(ë§›ìˆëŠ”), "Famous"(ìœ ëª…í•œ), "Good"(ì¢‹ì€), "Best"(ìµœê³ ), "JMT"(ì¡´ë§›).

    [Step 3 (Activity/Pub)]
    - Format: "{Location} {Noun}"  <-- NO Adjective!
    - Rule: Do NOT use adjectives. Just Location + Category Noun.

    # Mapping Rules (Select the best Adjective & Noun):

    [Step 1. Restaurant]
    - Adjectives (Select ONE):
      * Cheap/Quantity -> 'ê°€ì„±ë¹„'
      * Expensive/Anniversary -> 'ê¸°ë…ì¼', 'íŒŒì¸ë‹¤ì´ë‹'
      * Quiet/Talk -> 'ì¡°ìš©í•œ', 'ë£¸ì‹ë‹¹'
      * Old/Authentic -> 'ë…¸í¬'
      * Trendy/New -> 'ì‹ ìƒ'
      * Default -> 'ë§›ì§‘'
    - Nouns:
      * Specific Food: 'ì´ˆë°¥', 'íŒŒìŠ¤íƒ€', 'ê³ ê¸°ì§‘', 'ê³±ì°½', 'í‰ì–‘ëƒ‰ë©´' etc.
      * Category: 'ì¼ì‹', 'ì–‘ì‹', 'í•œì‹', 'ì¤‘ì‹'
      * Course: 'ì˜¤ë§ˆì¹´ì„¸'

    [Step 2. Cafe/Dessert]
    - Adjectives (Select ONE):
      * Photo/Insta -> 'í¬í† ì¡´', 'ê°ì„±'
      * Quiet/Study -> 'ì¡°ìš©í•œ', 'ì¹´ê³µ'
      * Big/Comfort -> 'ëŒ€í˜•', 'ì†ŒíŒŒê°€ í¸í•œ'
      * View -> 'ë·°ë§›ì§‘'
      * Default -> 'ë””ì €íŠ¸', 'ë¡œìŠ¤íŒ…'
    - Nouns:
      * MUST include: 'ì¹´í˜' or 'ì°»ì§‘' or specific dessert like 'ë¹™ìˆ˜', 'ì¼€ì´í¬'

    [Step 3. Activity/Pub]
    - Adjectives: NONE
    - Nouns:
      * Alcohol: 'ì´ìì¹´ì•¼', 'ì™€ì¸ë°”', 'ì¹µí…Œì¼ë°”', 'ë…¸í¬ í˜¸í”„', 'ì•¼ì¥'
      * Activity: 'ì½”ì¸ë…¸ë˜ë°©', 'ë³´ë“œê²Œì„ì¹´í˜', 'ë°©íƒˆì¶œ', 'ì…€í”„ì‚¬ì§„ê´€', 'ì˜í™”ê´€'

    # Constraints:
    - Output language: Korean.
    """

    completion = client.beta.chat.completions.parse(
        model="gpt-5.1",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": f"Chat Log:\n\n{text}"},
        ],
        response_format=AnalysisResult,
    )

    result = completion.choices[0].message.parsed

    # ---------------------------------------------------------
    # [Cache Save] ê²°ê³¼ Redis ì €ì¥
    # ---------------------------------------------------------
    if redis_client and cache_key:
        try:
            # Pydantic ê°ì²´ë¥¼ JSON ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥ (TTL: 24ì‹œê°„)
            redis_client.setex(cache_key, 86400, result.model_dump_json())
            print(f"ğŸ’¾ [Redis Saved] ê²°ê³¼ë¥¼ ìºì‹œì— ì €ì¥í–ˆìŠµë‹ˆë‹¤. (TTL: 24h)")
        except Exception as e:
            print(f"âš ï¸ Redis Write Error: {e}")

    return result